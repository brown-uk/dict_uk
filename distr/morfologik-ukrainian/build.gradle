apply plugin: 'java'
apply plugin: 'maven'
apply plugin: 'maven-publish'
apply plugin: 'signing'

String versionFile="${projectDir}/../../VERSION"
version=new File(versionFile).text.trim()

println "Version: $version"

group = 'ua.net.nlp'

String artifactId = 'morfologik-ukrainian-lt'
archivesBaseName = artifactId

sourceCompatibility = 1.8

String ltToolsVersion = '5.4-SNAPSHOT'

String langCode="uk"

String packageDir="org/languagetool/resource/" + langCode
String resourceDir=sourceSets.main.resources.srcDirs[0].toString() + "/" + packageDir
String outResDir=sourceSets.main.output.resourcesDir.toString() + "/" + packageDir
String outRulesDir=sourceSets.main.output.resourcesDir.toString() + "/org/languagetool/rules/uk"
String tmpDir="build/tmp"

String inputDir="${projectDir}/../../out"
String inputDictFile="dict_corp_lt.txt"


if( project.hasProperty('ltDir') ) {
  ext.languagetoolResDestDir = "$ltDir/languagetool-language-modules/uk/src/main/resources/org/languagetool/resource/uk"
  ext.languagetoolRulesDestDir = "$ltDir/languagetool-language-modules/uk/src/main/resources/org/languagetool/rules/uk"
}
else {
  logger.warn("WARNING: No 'ltDir' property set, deployment is disabled")
  //TODO: fail deployment tasks in a better way
  ext.languagetoolResDestDir = "/invalid_lt_dir"
  ext.languagetoolRulesDestDir = "/invalid_lt_dir"
}



repositories {
    mavenLocal()
    mavenCentral()
}

configurations{
  provided {
        description = 'Configuration for generating the dictionaries'
  }
}

dependencies {
    provided 'org.languagetool:languagetool-tools:' + ltToolsVersion
}



task tagList(type: Exec) {
    def srcDict="${inputDir}/$inputDictFile"
    def outFile="${outResDir}/ukrainian_tags.txt"

    inputs.file srcDict
    outputs.file outFile

    workingDir "$projectDir"

    def cmd = "cat ${srcDict} | awk '{ print \$3 }' | sort -u > ${outFile}"

    commandLine "sh", "-c", "${cmd}"
}


task prepareDict(type: Exec) {
    def srcDict="${inputDir}/$inputDictFile"
    def outFile="${tmpDir}/all.tagged.tmp"

    inputs.file srcDict
    outputs.file outFile

    workingDir "$projectDir"

    doFirst {
        println "Preparing dict file $inputDictFile"
        new File("$workingDir/$tmpDir").mkdirs()
    }

    def cmd = "cat ${srcDict} | tr ' ' '\\t' | LC_ALL=POSIX sort -u > ${outFile} && grep -vE ':(subst|vis)' ${outFile} > ${outFile}.synth"

    commandLine "sh", "-c", "${cmd}"
}


task posDict(type: JavaExec, dependsOn: prepareDict) {
    def outputDict="${outResDir}/ukrainian.dict"

    inputs.files tasks.prepareDict.outputs
    outputs.file outputDict

    workingDir "$projectDir"

    classpath = files(configurations.provided.files)
    main = 'org.languagetool.tools.POSDictionaryBuilder'

    args "-i", "${tmpDir}/all.tagged.tmp"
    args "-info", "${resourceDir}/ukrainian.info"
    args "-o", "${outputDict}"
}


task synthDict(type: JavaExec, dependsOn: prepareDict) {
    def outputDict="${outResDir}/ukrainian_synth.dict"

    inputs.files tasks.prepareDict.outputs.files
    outputs.file outputDict

    workingDir "$projectDir"

    classpath = files(configurations.provided.files)
    main = 'org.languagetool.tools.SynthDictionaryBuilder'

    args "-i", "${tmpDir}/all.tagged.tmp.synth"
    args "-info", "${resourceDir}/ukrainian_synth.info"
    args "-o", "${outputDict}"
}


task prepareSpellWords(type: Exec) {
    def srcDict="${inputDir}/words_spell.txt"
    def outFile="${tmpDir}/spell.words.tmp"

    inputs.file srcDict
    outputs.file outFile

    workingDir "$projectDir"

    doFirst {
        new File(tmpDir).mkdirs()
    }

    def cmd = "cat ${srcDict} | LC_ALL=POSIX sort -u > ${outFile}"

    commandLine "sh", "-c", "${cmd}"
}


task spellDict(type: JavaExec, dependsOn: prepareSpellWords) {
    def spellOutDir="${outResDir}/hunspell"
    def outFile="${spellOutDir}/uk_UA.dict"
    def freqFile="src/main/data/uk_wordlist.xml"

    inputs.files tasks.prepareSpellWords.outputs.files, "src/data/uk_wordlist.xml"
    outputs.file outFile

    workingDir "$projectDir"

    classpath = files(configurations.provided.files)
    main = 'org.languagetool.tools.SpellDictionaryBuilder'

    args "-i", "${tmpDir}/spell.words.tmp"
    args "-info", "${resourceDir}/hunspell/uk_UA.info"
    args "-o", "${outFile}"
    args "-freq", "${freqFile}"

    doFirst() {
        new File(spellOutDir).mkdirs()
    }
}




task createOutRulesDir {
  doLast() {
    println "Preparing dict file $outRulesDir"
    new File("$outRulesDir").mkdirs()
  }
}


task createReplacementDict(dependsOn: createOutRulesDir) {
    def srcDir="${inputDir}/../data/dict"
    def outFile="$outRulesDir/replace.txt"

    inputs.files "$srcDir/twisters.lst", "$srcDir/invalid.lst", "$srcDir/invalid-compound.lst", "$srcDir/invalid-auto-replace.txt", "$srcDir/subst.lst", "$srcDir/invalid-composite.lst"
    outputs.file outFile

    doLast {

		def headText =
'''# Simple replace table
# Format: word=suggestion1|suggestion2|suggestion3...

'''
		def outLines = []
		inputs.files.each { File file ->
			file.eachLine "UTF-8", {
				if( it.startsWith('#') || ! it.contains(' #>') )
					return

				if( file.name.contains('composite') ) {
					it = it.replaceFirst(/^([а-яіїєґА-ЯІЇЄҐ'-]+).*? - ([а-яіїєґА-ЯІЇЄҐ'-]+).*#> *(.*)/, '$1-$2=$3')
					outLines << it
				}	
				else {
					it = it.replace(' +cs=', '')
					it = it.replaceFirst(/^([а-яіїєґА-ЯІЇЄҐ'-]+).*#> *(.*)(#ok:.*)?/, '$1=$2')
					outLines << it
				}			
			}
		}
		
		new File(outFile).text = headText + outLines.join("\n") + '\n'
		println "Wrote ${outLines.size} replacements"
	}

}



task createSoftReplacementDict(dependsOn: createOutRulesDir) {
    def srcDir="${inputDir}/../data/dict"
    def outFile="${outRulesDir}/replace_soft.txt"
    def allFiles = Arrays.asList(new File(srcDir).listFiles())
    def srcFiles = allFiles.findAll{ it.name.endsWith('.lst') && ! (it.name =~ /(twisters|subst|invalid.*)\.lst/) }

    inputs.files srcFiles
    outputs.file outFile


    doLast {

        def headText =
'''# Simple replace table for soft suggestions
# Format: word=suggestion1|suggestion2|suggestion3...

'''
        def outLines = getReplacements(srcDir, srcFiles, { ! it.contains('ua_1992')})

        println "Wrote ${outLines.size} replacements"
        new File(outFile).text = headText + outLines.join('\n') + "\n"
    }
}


task createNewSpellingReplacementDict(dependsOn: createOutRulesDir) {
    def srcDir="${inputDir}/../data/dict"
    def outFile="${outRulesDir}/replace_spelling_2019.txt"
    def allFiles = Arrays.asList(new File(srcDir).listFiles())
    def srcFiles = allFiles.findAll{ 
        (it.name.endsWith('.lst') 
                && ! (it.name in ['twisters.lst', 'base-composite.lst', 'subst.lst', 'names-other.lst'])) \
            || it.name.endsWith("-auto-replace.txt") }

    inputs.files srcFiles
    outputs.file outFile


    doLast {

        def headText =
'''# Simple replace table for 2019 spelling suggestions
# Format: word=suggestion1|suggestion2|suggestion3...

'''
        def outLines = getReplacements(srcDir, srcFiles, {it.contains('ua_1992')})

        println "Wrote ${outLines.size} replacements"
        new File(outFile).text = headText + outLines.join('\n') + "\n"
    }
}

List<String> getReplacements(String srcDir, List<File> files, Closure filter) {
    def outLines = []

    files.each{ srcFile ->
        def rvLines = new File("$srcDir/$srcFile.name").readLines()
        .findAll {
            ! it.startsWith('#') && it.contains(' #> ') && filter(it)
        }.collect{
            it = it.replace(' +cs=', '')
            it = it.replaceFirst(/^([а-яіїєґА-ЯІЇЄҐ'-]+).*#> *(.*)(#ok:.*)?/, '$1=$2')
            it = it.replaceFirst(/ *# rv_...(\|rv_...)* */, '')
        }

        outLines.addAll(rvLines)
    }

    java.text.Collator coll = java.text.Collator.getInstance(new Locale("uk", "UA"))
    Collections.sort(outLines, coll)

    outLines
}


task createRenamedReplacementDict(dependsOn: createOutRulesDir) {
    def srcDir="${inputDir}/../data/dict"
    def outFile="${outRulesDir}/replace_renamed.txt"
    def allFiles = Arrays.asList(new File(srcDir).listFiles())
    def srcFiles = allFiles.findAll{ it.name.endsWith('.lst') && ! it.name.startsWith('twisters') }

    inputs.files srcFiles
    outputs.file outFile


    def headText =
'''# Simple replace table for soft suggestions
# Format: name=replacemet|(optional) explanation

'''
    doLast {
		def outLines = []

		srcFiles.each{ File srcFile ->
			def rvLines = new File("$srcDir/$srcFile.name").text
			    .split('\n')
			    .findAll {
                    ! it.startsWith('#') && it.contains(' #>> ')
			    }.collect{
                    if( srcFile.name.contains('composite') ) {
                        it = it.replaceFirst(/ \/.* - /, '-')
                    }
//                    it = it.replace(' +cs=', '')
                    it = it.replaceFirst(/^([а-яіїєґА-ЯІЇЄҐ'-]+).*#>> *(.*)(#ok:.*)?/, '$1=$2')
                    it = it.replaceFirst(/ *# rv_...(\|rv_...)* */, '')
			    }

			outLines.addAll(rvLines)
		}

		java.text.Collator coll = java.text.Collator.getInstance(new Locale("uk", "UA"))
        Collections.sort(outLines, coll)
		
        println "Wrote $outLines.size replacements"
		new File(outFile).text = headText + outLines.join('\n') + "\n"
	}

}



task caseGovernmentDict() {
    def srcDir="${inputDir}/../data/dict"
    def outFile="${outResDir}/case_government.txt"
    def srcFiles=["base.lst", "twisters.lst", "invalid-compound.lst", "slang.lst", "exceptions.lst", "pronouns.lst", "arch.lst", "subst.lst"]

    inputs.files srcFiles.collect{ "$srcDir/$it" }
    outputs.file outFile

    doFirst {
        new File(outResDir).mkdirs()
    }

    doLast {
        def outLines = []

        srcFiles.each{ srcFile ->

            def rvLines = new File("$srcDir/$srcFile")
                .readLines('UTF-8')
                .findAll{
                    (it =~ ' /(adj|n[0-4])| (prep|noninfl:&predic)' || it.contains("+cs=")) && it.contains(' rv_')
                }.collect{
//                def out = it.contains(" +cs=") ? it.replaceFirst(/^ \+cs=(.*?) .* (rv_...(:rv_...)*).*?$/, '$1 $2\nнай$1 $2') \
                    def out = it.contains(" +cs=") ? it.contains("rv-най") \
                                                 ? it.replaceFirst(/^ \+cs=(.*?) .* (rv_...(:rv_...)*).*?$/, '$1 $2\nнай$1 $2') \
                                                 : it.replaceFirst(/^ \+cs=(.*?) .* (rv_...(:rv_...)*).*?$/, '$1 $2') \
                                               : it.replaceFirst(/^(.*?) .* (rv_...(:rv_...)*).*?$/, '$1 $2')
                   out.replace("rv_", "v_")
                }

            outLines.addAll(rvLines)
        }

        println "Wrote $outLines.size lines"
        new File(outFile).text = outLines.join('\n') + '\n'
    }
}


task helperDicts (dependsOn: [caseGovernmentDict, createReplacementDict, createSoftReplacementDict, createNewSpellingReplacementDict])


task deployDictToLT(type: Copy, dependsOn: resources) {
    from outResDir
    into "${languagetoolResDestDir}"

    includeEmptyDirs = false

//    with dataContent
}



task deployReplacements(type: Copy, dependsOn: [createReplacementDict, createSoftReplacementDict, createRenamedReplacementDict, createNewSpellingReplacementDict]) {
    doFirst() {
        logger.lifecycle "Deploying to LT dir: ${languagetoolRulesDestDir}"
    }

    from outRulesDir
    into "${languagetoolRulesDestDir}"
    include "**/replace*.txt"

    includeEmptyDirs = false
}

task deployCaseGovernment(type: Copy, dependsOn: caseGovernmentDict) {
    doFirst() {
        logger.lifecycle "Deploying to LT dir: ${languagetoolResDestDir}"
    }
//        from outResDir
        from caseGovernmentDict
        into "${languagetoolResDestDir}"
//        include "**/case_*.txt"

        includeEmptyDirs = false
}

task deployHelperDictsToLT(dependsOn: [deployReplacements, deployCaseGovernment])

task deployLtDict(dependsOn: [publish, deployHelperDictsToLT])



jar {
    inputs.file versionFile

    manifest {
        attributes 'Implementation-Title': 'Ukrainian binary Morfologik dictionaries for LanguageTool',
                   'Implementation-Version': version
    }

    setArchiveName "${artifactId}-${version}.jar"

      include 'org/languagetool/**/*.dict'
      include 'org/languagetool/**/*.info'
      include 'org/languagetool/**/README*'
      include 'org/languagetool/**/*tags*.txt'

    includeEmptyDirs false
}


processResources.dependsOn(posDict, synthDict, tagList, spellDict, caseGovernmentDict, createReplacementDict)
compileJava.enabled = false


signing {
    sign configurations.archives
}



publishing {
    repositories {
        mavenLocal()
    }

    publications {
        mavenJava(MavenPublication) {
            from components.java
            //artifact dictJar
            //artifact ltJar
        }
    }
}


uploadArchives {
  inputs.files "$projectDir/../../VERSION"

  repositories {

    mavenDeployer {
      beforeDeployment { MavenDeployment deployment -> signing.signPom(deployment) }

      repository(url: "https://oss.sonatype.org/service/local/staging/deploy/maven2/") {
        authentication(userName: ossrhUsername, password: ossrhPassword)
      }

      snapshotRepository(url: "https://oss.sonatype.org/content/repositories/snapshots/") {
        authentication(userName: getProperty('ossrhUsername') ?: '', password: getProperty('ossrhPassword') ?: '')
      }


      pom.project {
        name 'Ukrainian Morfologik dictionaries for LanguageTool'
        packaging 'jar'
        artifactId = "${artifactId}-${version}"
//        artifactId = "xxx-${version}"
        // optionally artifactId can be defined here 
        description 'Ukrainian part-of-speech dictionaries in Morfologik binary format'
        url 'https://github.com/brown-uk/dict_uk'

        scm {
          url 'https://github.com/brown-uk/dict_uk.git'
        }

        licenses {
          license {
            name 'GNU Lesser General Public License'
            url 'http://www.gnu.org/licenses/lgpl.txt'
          }
        }

        developers {
          developer {
            id 'arysin'
            name 'Andriy Rysin'
            email 'arysin@gmail.com'
          }
        }
      }


    }
  }
}
