apply plugin: 'java'
apply plugin: 'maven'
apply plugin: 'maven-publish'
apply plugin: 'signing'

version=new File("${projectDir}/../../VERSION").text.trim()

println "Version: $version"

group = 'ua.net.nlp'

String artifactId = 'morfologik-ukrainian-search'
archivesBaseName = artifactId

String ltToolsVersion = '4.9-SNAPSHOT'

String langCode="uk"

String packageDir="ua/net/nlp"
String resourceDir=sourceSets.main.resources.srcDirs[0].toString() + "/" + packageDir
String outResDir=sourceSets.main.output.resourcesDir.toString() + "/" + packageDir
String tmpDir="build/tmp"


String inputDir="${projectDir}/../../out"
String inputDictFile="dict_corp_lt.txt"

String dstEncoding="utf-8"
String srcEncoding="utf-8"



repositories {
    mavenLocal()
    mavenCentral()
}

configurations{
  provided {
        description = 'Configuration for generating the dictionaries'
  }
}

dependencies {
    provided 'org.languagetool:languagetool-tools:' + ltToolsVersion
}


task prepareDict() {
    def srcDict="${inputDir}/$inputDictFile"
    def outFile="${tmpDir}/all.tagged.nlp.tmp"
    def splitter = '\t'
    def tagSplitter = '|'
    def cnt = 0
	def forceSquashLemmas = true

    inputs.file srcDict
    outputs.file outFile

    doLast {
        println "Preparing dict file $inputDictFile"
        new File("$projectDir/$tmpDir").mkdirs()

        def outF = new File(outFile)
        outF.text = ''

        // to lower memory footprint we collect by lemmas

        def prevLemma = ""
        def tagMap = [:].withDefault{new LinkedHashSet<>()}

        def gKeys = new HashSet<>()
        def currGKeys = new HashSet<>()

        new File(srcDict).eachLine { String line ->
          line = line.replace('ґ', 'г').replace('Ґ', 'Г')
		  
          def (word, lemma, tagStr) = line.split()

		  tagStr = tagStr.replaceAll(/:(up[0-9]{2}|alt|bad|coll|slang|rare|xp[0-9])/, '')
		  if( forceSquashLemmas ) {
			  tagStr = tagStr.replaceAll(/:(prop|geo|.name)/, '')
//			  lemma = lemma.toLowerCase()
		  }

          def wordKey = word.toLowerCase() + splitter + lemma

          boolean withG = lemma.contains('г') || lemma.contains('Г')
          if( withG ) {
            if( wordKey in gKeys ) {
              return
            }
          }

          if( lemma != prevLemma ) {
            tagMap.each { key, tags ->
              def outLine = key + splitter + tags.join(tagSplitter) + "\n"
              outF.append(outLine, dstEncoding)
              if( ++cnt % 100000 == 0 ) println "$cnt"
            }
            tagMap.clear()

            if( currGKeys ) {
                gKeys.addAll( currGKeys )
                currGKeys.clear()
            }

            prevLemma = lemma
          }
		  
		  if( withG ) {
			  currGKeys << wordKey
		  }

          tagMap[wordKey] << tagStr
        }

        tagMap.each { key, tags ->
            def outLine = key + splitter + tags.join(tagSplitter) + "\n"
            outF.append(outLine, dstEncoding)
        }
    }

}


task posDict(type: JavaExec, dependsOn: prepareDict) {
    def outputDict="${outResDir}/ukrainian.dict"

    inputs.files tasks.prepareDict.outputs
    outputs.file outputDict

    workingDir "$projectDir"

    classpath = files(configurations.provided.files)
    main = 'org.languagetool.tools.POSDictionaryBuilder'

    args "-i", tasks.prepareDict.outputs.getFiles().iterator().next()
    args "-info", "${resourceDir}/ukrainian.info"
    args "-o", "${outputDict}"
    
    doFirst {
        new File(outputDict).mkdirs()
    }
}


task copyExtraFiles(type: Copy) {
  from("$projectDir/../../doc/tags.txt")
  into (sourceSets.main.output.resourcesDir.absolutePath + '/ua/net/nlp/')
  rename("tags.txt", "tagset.txt")
}


jar {
    manifest {
        attributes 'Implementation-Title': 'Ukrainian part-of-speech (POS) dictionary for searching as a Morfologik binary',
                   'Implementation-Version': version
    }

    setArchiveName "${artifactId}-${version}.jar"

//    from(sourceSets.main.output) {
        include '**/ua/net/nlp/*'
//    }

    includeEmptyDirs false
}

jar.dependsOn(posDict)

processResources.dependsOn(copyExtraFiles)


//classes.dependsOn(createPOSDict, createSynthDict, createTagList, createSpellDict, createCaseGovernmentDict)
compileJava.enabled = false

signing {
    sign configurations.archives
}



publishing {
    repositories {
        mavenLocal()
    }

    publications {
        mavenJava(MavenPublication) {
            setArtifactId('morfologik-ukrainian-search')

            from components.java
        }
    }
}


uploadArchives {
  repositories {
    mavenDeployer {
      beforeDeployment { MavenDeployment deployment -> signing.signPom(deployment) }

      repository(url: "https://oss.sonatype.org/service/local/staging/deploy/maven2/") {
        authentication(userName: ossrhUsername, password: ossrhPassword)
      }

      snapshotRepository(url: "https://oss.sonatype.org/content/repositories/snapshots/") {
        authentication(userName: ossrhUsername, password: ossrhPassword)
      }

      pom.project {
        name 'Ukrainian POS tag dictionary for Morfologik'
        packaging 'jar'
        // optionally artifactId can be defined here 
        description 'Ukrainian part-of-speech dictionaries in Morfologik binary format'
        url 'https://github.com/brown-uk/dict_uk'

        scm {
          url 'https://github.com/brown-uk/dict_uk.git'
        }

        licenses {
          license {
            name 'The Apache Software License, Version 2.0'
            url 'http://www.apache.org/licenses/LICENSE-2.0.txt'
          }
        }

        developers {
          developer {
            id 'arysin'
            name 'Andriy Rysin'
            email 'arysin@gmail.com'
          }
        }
      }

    }
  }
}
